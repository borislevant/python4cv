{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_from_softmax_to_transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/borislevant/CourseraMachineLearning/blob/master/cifar10_from_softmax_to_transfer.ipynb",
      "authorship_tag": "ABX9TyNryaLC+RV1Jrftv84EVZE6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borislevant/SciComPy/blob/master/cifar10_from_softmax_to_transfer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will demonstrate the work on the CIFAR-10 data set from the simplest Softmax model (Logistic regression) to the more advanced methods"
      ],
      "metadata": {
        "id": "7dy5Gp7sziul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "The CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10\n",
        "classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets\n",
        "provides 10,000 images. This image taken from the CIFAR repository ( <a href = \"https://www.cs.toronto.edu/~kriz/cifar.html\">https://www.cs.toronto.edu/~kriz/cifar.html </a>). This is a classification problem with 10 classes(muti-label classification). We can take a view on this image for more comprehension of the dataset. \n",
        "\n",
        "![cifar10.png](https://github.com/borislevant/SciComPy/blob/master/cifar10.png?raw=1)\n",
        "\n",
        "\n",
        "The challenge is to recognize previously unseen images and assign them to one of the 10 classes.\n",
        "\n",
        "Ok Let's get started."
      ],
      "metadata": {
        "id": "ODkXzxzJX4RV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import and Preprocess the data\n",
        "\n"
      ],
      "metadata": {
        "id": "8loO1ZCAYNFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Import all required libraries"
      ],
      "metadata": {
        "id": "CQEVEyzgcsQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, InputLayer\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "RxZygPoMYOJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32  # The default batch size of keras.\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "epochs = 30\n",
        "data_augmentation = False\n",
        "\n",
        "opt = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "reg = keras.regularizers.l2(l2=0.0001)"
      ],
      "metadata": {
        "id": "Q1nImjQpciHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Import and preproces of data \n",
        "We load the data and split it between train and test sets\n"
      ],
      "metadata": {
        "id": "od0ht3ORYW_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vQGeMoaYZeP",
        "outputId": "7a72300a-e559-4bac-9dd6-bd8a8b99a592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data. Before we need to connvert data type to float for computation.\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "bMdzujJVcfoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Softmax model"
      ],
      "metadata": {
        "id": "vJ6g0nKpaVf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=x_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=reg))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHHh5oltaVDa",
        "outputId": "924e5724-ef63-4bdc-ce46-1820b99b42bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_softmax', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_softmax.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nstz6VYcaBw1",
        "outputId": "99c63dbd-e5ce-48bc-a9e2-59be4229d66a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 8s 3ms/step - loss: 1.9777 - accuracy: 0.2990 - val_loss: 1.8886 - val_accuracy: 0.3317\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8490 - accuracy: 0.3556 - val_loss: 1.8369 - val_accuracy: 0.3463\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8153 - accuracy: 0.3705 - val_loss: 1.8171 - val_accuracy: 0.3681\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7950 - accuracy: 0.3794 - val_loss: 1.7877 - val_accuracy: 0.3801\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7793 - accuracy: 0.3838 - val_loss: 1.7905 - val_accuracy: 0.3777\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7698 - accuracy: 0.3905 - val_loss: 1.7745 - val_accuracy: 0.3898\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7623 - accuracy: 0.3939 - val_loss: 1.7657 - val_accuracy: 0.3908\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7540 - accuracy: 0.3956 - val_loss: 1.7542 - val_accuracy: 0.3966\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7473 - accuracy: 0.3975 - val_loss: 1.7682 - val_accuracy: 0.3836\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7399 - accuracy: 0.4046 - val_loss: 1.7568 - val_accuracy: 0.3907\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7371 - accuracy: 0.4042 - val_loss: 1.7449 - val_accuracy: 0.3986\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7320 - accuracy: 0.4069 - val_loss: 1.7556 - val_accuracy: 0.3891\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7285 - accuracy: 0.4097 - val_loss: 1.7514 - val_accuracy: 0.3876\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7266 - accuracy: 0.4090 - val_loss: 1.7415 - val_accuracy: 0.3949\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7225 - accuracy: 0.4114 - val_loss: 1.7452 - val_accuracy: 0.3988\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7188 - accuracy: 0.4135 - val_loss: 1.7390 - val_accuracy: 0.3992\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7171 - accuracy: 0.4121 - val_loss: 1.7401 - val_accuracy: 0.4002\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7145 - accuracy: 0.4131 - val_loss: 1.7397 - val_accuracy: 0.3927\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7116 - accuracy: 0.4141 - val_loss: 1.7625 - val_accuracy: 0.3863\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7107 - accuracy: 0.4150 - val_loss: 1.7560 - val_accuracy: 0.3901\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7069 - accuracy: 0.4182 - val_loss: 1.7451 - val_accuracy: 0.3916\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7050 - accuracy: 0.4176 - val_loss: 1.7504 - val_accuracy: 0.3925\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7047 - accuracy: 0.4184 - val_loss: 1.7351 - val_accuracy: 0.3989\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7014 - accuracy: 0.4182 - val_loss: 1.7286 - val_accuracy: 0.3988\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6996 - accuracy: 0.4204 - val_loss: 1.7332 - val_accuracy: 0.4002\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6994 - accuracy: 0.4210 - val_loss: 1.7294 - val_accuracy: 0.4002\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6979 - accuracy: 0.4208 - val_loss: 1.7390 - val_accuracy: 0.3925\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6966 - accuracy: 0.4229 - val_loss: 1.7246 - val_accuracy: 0.4052\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6944 - accuracy: 0.4219 - val_loss: 1.7297 - val_accuracy: 0.4059\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6925 - accuracy: 0.4232 - val_loss: 1.7317 - val_accuracy: 0.4006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Fully-connected Neural Network (FNN) model"
      ],
      "metadata": {
        "id": "NNNPoEFCfWZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer(input_shape=x_train.shape[1:]))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu', kernel_regularizer=reg))\n",
        "model.add(Dense(256, activation='relu', kernel_regularizer=reg))\n",
        "model.add(Dense(64, activation='relu', kernel_regularizer=reg))\n",
        "model.add(Dense(num_classes, activation='softmax', kernel_regularizer=reg))\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQ6jPs0FfV_-",
        "outputId": "fb04035a-0de2-47c1-848c-0fc348e08809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              3146752   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,426,250\n",
            "Trainable params: 3,426,250\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_fnn', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_fnn.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v44TLZmOftmC",
        "outputId": "a8e01e53-e658-4b31-ad6f-a0b2540fbc9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.9790 - accuracy: 0.3381 - val_loss: 1.7979 - val_accuracy: 0.3974\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.7534 - accuracy: 0.4076 - val_loss: 1.6873 - val_accuracy: 0.4346\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.6597 - accuracy: 0.4366 - val_loss: 1.6427 - val_accuracy: 0.4386\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5939 - accuracy: 0.4563 - val_loss: 1.5857 - val_accuracy: 0.4586\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.5461 - accuracy: 0.4705 - val_loss: 1.5381 - val_accuracy: 0.4798\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5097 - accuracy: 0.4845 - val_loss: 1.5385 - val_accuracy: 0.4783\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.4797 - accuracy: 0.4933 - val_loss: 1.5212 - val_accuracy: 0.4808\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.4502 - accuracy: 0.5050 - val_loss: 1.5270 - val_accuracy: 0.4794\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.4251 - accuracy: 0.5172 - val_loss: 1.4747 - val_accuracy: 0.4960\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3984 - accuracy: 0.5255 - val_loss: 1.4734 - val_accuracy: 0.5002\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3780 - accuracy: 0.5336 - val_loss: 1.4565 - val_accuracy: 0.5050\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3563 - accuracy: 0.5416 - val_loss: 1.4367 - val_accuracy: 0.5112\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.3340 - accuracy: 0.5489 - val_loss: 1.4388 - val_accuracy: 0.5115\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.3149 - accuracy: 0.5583 - val_loss: 1.4107 - val_accuracy: 0.5247\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2970 - accuracy: 0.5655 - val_loss: 1.4165 - val_accuracy: 0.5245\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2792 - accuracy: 0.5744 - val_loss: 1.4002 - val_accuracy: 0.5313\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2597 - accuracy: 0.5812 - val_loss: 1.4394 - val_accuracy: 0.5141\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2450 - accuracy: 0.5854 - val_loss: 1.4210 - val_accuracy: 0.5232\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2303 - accuracy: 0.5902 - val_loss: 1.3979 - val_accuracy: 0.5358\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2157 - accuracy: 0.5959 - val_loss: 1.3888 - val_accuracy: 0.5363\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1955 - accuracy: 0.6044 - val_loss: 1.3938 - val_accuracy: 0.5348\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1821 - accuracy: 0.6066 - val_loss: 1.4032 - val_accuracy: 0.5286\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1668 - accuracy: 0.6148 - val_loss: 1.3918 - val_accuracy: 0.5420\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1527 - accuracy: 0.6202 - val_loss: 1.3919 - val_accuracy: 0.5415\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1392 - accuracy: 0.6234 - val_loss: 1.4118 - val_accuracy: 0.5306\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1245 - accuracy: 0.6309 - val_loss: 1.3809 - val_accuracy: 0.5458\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1104 - accuracy: 0.6364 - val_loss: 1.3913 - val_accuracy: 0.5402\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0985 - accuracy: 0.6401 - val_loss: 1.3624 - val_accuracy: 0.5536\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0842 - accuracy: 0.6465 - val_loss: 1.3960 - val_accuracy: 0.5426\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0715 - accuracy: 0.6512 - val_loss: 1.3768 - val_accuracy: 0.5473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Convolutional Neural Network"
      ],
      "metadata": {
        "id": "vd2oGltPMKq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define the convnet\n",
        "model = Sequential()\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# CONV => RELU => CONV => RELU => POOL => DROPOUT\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# FLATTERN => DENSE => RELU => DROPOUT\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# a softmax classifier\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8znMBMaGNNss",
        "outputId": "8e09b234-a8c4-497f-fc41-30f6f5ad0ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " activation (Activation)     (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 30, 30, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 15, 15, 64)        0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 13, 13, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 64)          0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               1180160   \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_cnn', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_cnn.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLQEK30PBAw",
        "outputId": "ae85a46a-ce37-4085-c159-c007bab4a99d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 18s 6ms/step - loss: 1.6483 - accuracy: 0.3976 - val_loss: 1.3792 - val_accuracy: 0.5011\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 1.3807 - accuracy: 0.5019 - val_loss: 1.2451 - val_accuracy: 0.5590\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.2674 - accuracy: 0.5487 - val_loss: 1.1484 - val_accuracy: 0.5870\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.1862 - accuracy: 0.5812 - val_loss: 1.1117 - val_accuracy: 0.6027\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1223 - accuracy: 0.6021 - val_loss: 1.0650 - val_accuracy: 0.6240\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 1.0699 - accuracy: 0.6220 - val_loss: 0.9800 - val_accuracy: 0.6575\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.0218 - accuracy: 0.6403 - val_loss: 0.9388 - val_accuracy: 0.6676\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9785 - accuracy: 0.6571 - val_loss: 0.9158 - val_accuracy: 0.6818\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.9409 - accuracy: 0.6693 - val_loss: 0.8666 - val_accuracy: 0.6986\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8993 - accuracy: 0.6840 - val_loss: 0.8636 - val_accuracy: 0.7005\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8688 - accuracy: 0.6983 - val_loss: 0.8201 - val_accuracy: 0.7136\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.8402 - accuracy: 0.7076 - val_loss: 0.8047 - val_accuracy: 0.7257\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8136 - accuracy: 0.7158 - val_loss: 0.7904 - val_accuracy: 0.7238\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7859 - accuracy: 0.7270 - val_loss: 0.7524 - val_accuracy: 0.7412\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7610 - accuracy: 0.7323 - val_loss: 0.7466 - val_accuracy: 0.7433\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.7358 - accuracy: 0.7444 - val_loss: 0.7293 - val_accuracy: 0.7486\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.7142 - accuracy: 0.7531 - val_loss: 0.7171 - val_accuracy: 0.7531\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6998 - accuracy: 0.7551 - val_loss: 0.7037 - val_accuracy: 0.7587\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6785 - accuracy: 0.7615 - val_loss: 0.6894 - val_accuracy: 0.7602\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6610 - accuracy: 0.7677 - val_loss: 0.6766 - val_accuracy: 0.7646\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6433 - accuracy: 0.7769 - val_loss: 0.7092 - val_accuracy: 0.7548\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6206 - accuracy: 0.7811 - val_loss: 0.6870 - val_accuracy: 0.7635\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6099 - accuracy: 0.7864 - val_loss: 0.6659 - val_accuracy: 0.7709\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5899 - accuracy: 0.7917 - val_loss: 0.6618 - val_accuracy: 0.7736\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5771 - accuracy: 0.7978 - val_loss: 0.6520 - val_accuracy: 0.7753\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5624 - accuracy: 0.8009 - val_loss: 0.6483 - val_accuracy: 0.7788\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5433 - accuracy: 0.8084 - val_loss: 0.6466 - val_accuracy: 0.7791\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 10s 6ms/step - loss: 0.5369 - accuracy: 0.8126 - val_loss: 0.6539 - val_accuracy: 0.7768\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.5250 - accuracy: 0.8179 - val_loss: 0.6258 - val_accuracy: 0.7840\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5101 - accuracy: 0.8204 - val_loss: 0.6255 - val_accuracy: 0.7853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Transfer learning\n"
      ],
      "metadata": {
        "id": "I3w8UctjMAQw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n"
      ],
      "metadata": {
        "id": "AVDQG_axMeLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vgg16(name, weights='imagenet', optimizer='adam'):\n",
        "    \n",
        "    # load model\n",
        "    model = VGG16(weights=weights, include_top=False, input_shape=(32,32,3))\n",
        "    \n",
        "    # freeze all layer\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # add new classifier head\n",
        "    x = GlobalAveragePooling2D()(model.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    # instantiate new model\n",
        "    myModel = keras.Model(inputs=model.input, outputs=predictions, name=name)\n",
        "\n",
        "    # unfreeze selected layer\n",
        "    #for layer in myModel.layers[unfreeze_from:]:\n",
        "    #    layer.trainable = True\n",
        "          \n",
        "    # compile model\n",
        "    myModel.compile(\n",
        "          loss='categorical_crossentropy',\n",
        "          optimizer=opt, \n",
        "          metrics=['accuracy']\n",
        "    )\n",
        "          \n",
        "    # print parameters\n",
        "    myModel.summary()\n",
        "    \n",
        "    return myModel\n",
        "\n",
        "def build_resnet50(name, weights='imagenet', optimizer='adam'):\n",
        "    \n",
        "    # load model\n",
        "    model = ResNet50(weights=weights, include_top=False, input_shape=(32,32,3))\n",
        "    \n",
        "    # freeze all layer\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # add new classifier head\n",
        "    x = GlobalAveragePooling2D()(model.output)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    # instantiate new model\n",
        "    myModel = keras.Model(inputs=model.input, outputs=predictions, name=name)\n",
        "\n",
        "    # unfreeze selected layer\n",
        "    #for layer in myModel.layers[unfreeze_from:]:\n",
        "    #    layer.trainable = True\n",
        "          \n",
        "    # compile model\n",
        "    myModel.compile(\n",
        "          loss='categorical_crossentropy',\n",
        "          optimizer=opt, \n",
        "          metrics=['accuracy']\n",
        "    )\n",
        "          \n",
        "    # print parameters\n",
        "    myModel.summary()\n",
        "    \n",
        "    return myModel\n",
        "\n",
        "def build_model(name, weights='imagenet', cut_at=-1, unfreeze_from=0, optimizer='adam'):\n",
        "    \n",
        "    # load model\n",
        "    model = VGG16(weights=weights, include_top=False, input_shape=(32,32,3))\n",
        "    \n",
        "    # freeze all layer\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        "    \n",
        "    # select layer output\n",
        "    if cut_at==-1:\n",
        "        x = model.output\n",
        "    else:\n",
        "        x = model.layers[cut_at].output\n",
        "        \n",
        "    # add new classifier head\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    predictions = Dense(10, activation='softmax')(x)\n",
        "\n",
        "    # instantiate new model\n",
        "    myModel = keras.Model(inputs=model.input, outputs=predictions, name=name)\n",
        "\n",
        "    # unfreeze selected layer\n",
        "    #for layer in myModel.layers[unfreeze_from:]:\n",
        "    #    layer.trainable = True\n",
        "          \n",
        "    # compile model\n",
        "    myModel.compile(\n",
        "          loss='categorical_crossentropy',\n",
        "          optimizer=opt, \n",
        "          metrics=['accuracy']\n",
        "    )\n",
        "          \n",
        "    # print parameters\n",
        "    myModel.summary()\n",
        "    \n",
        "    return myModel\n"
      ],
      "metadata": {
        "id": "miORxNelR3bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = build_model('full_scratch', weights=None)\n",
        "model = build_vgg16('full_scratch', weights='imagenet', unfreeze_from=19, optimizer=opt)\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_vgg_imagenet', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_vgg_imagenet.csv')\n"
      ],
      "metadata": {
        "id": "i1Lyx4sOR4eh",
        "outputId": "497f6567-6fb8-47d7-eabe-d77930a22c82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n",
            "Model: \"full_scratch\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 32, 32, 64)        1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 16, 16, 128)       147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 8, 8, 128)         0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 8, 8, 256)         295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 8, 8, 256)         590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 4, 4, 256)         0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 4, 4, 512)         1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 4, 4, 512)         2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 2, 2, 512)         0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 2, 2, 512)         2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 512)              0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,245,130\n",
            "Trainable params: 530,442\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 30s 13ms/step - loss: 1.4635 - accuracy: 0.4939 - val_loss: 1.2928 - val_accuracy: 0.5486\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 1.2191 - accuracy: 0.5757 - val_loss: 1.2005 - val_accuracy: 0.5798\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 20s 12ms/step - loss: 1.1509 - accuracy: 0.5998 - val_loss: 1.1790 - val_accuracy: 0.5864\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 1.1051 - accuracy: 0.6142 - val_loss: 1.1544 - val_accuracy: 0.5937\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 1.0713 - accuracy: 0.6280 - val_loss: 1.1307 - val_accuracy: 0.5994\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 1.0402 - accuracy: 0.6368 - val_loss: 1.1199 - val_accuracy: 0.6099\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 1.0086 - accuracy: 0.6498 - val_loss: 1.1133 - val_accuracy: 0.6086\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.9826 - accuracy: 0.6579 - val_loss: 1.1169 - val_accuracy: 0.6098\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.9579 - accuracy: 0.6665 - val_loss: 1.0926 - val_accuracy: 0.6152\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.9295 - accuracy: 0.6767 - val_loss: 1.0877 - val_accuracy: 0.6174\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9073 - accuracy: 0.6844 - val_loss: 1.1026 - val_accuracy: 0.6172\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8827 - accuracy: 0.6925 - val_loss: 1.1086 - val_accuracy: 0.6138\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.8602 - accuracy: 0.6996 - val_loss: 1.0837 - val_accuracy: 0.6224\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.8378 - accuracy: 0.7092 - val_loss: 1.0852 - val_accuracy: 0.6236\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.8147 - accuracy: 0.7167 - val_loss: 1.0872 - val_accuracy: 0.6273\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7947 - accuracy: 0.7247 - val_loss: 1.0883 - val_accuracy: 0.6260\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7725 - accuracy: 0.7319 - val_loss: 1.1083 - val_accuracy: 0.6243\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 20s 13ms/step - loss: 0.7523 - accuracy: 0.7385 - val_loss: 1.0991 - val_accuracy: 0.6254\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7302 - accuracy: 0.7467 - val_loss: 1.1080 - val_accuracy: 0.6281\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.7099 - accuracy: 0.7542 - val_loss: 1.1190 - val_accuracy: 0.6252\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6900 - accuracy: 0.7621 - val_loss: 1.1176 - val_accuracy: 0.6256\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6694 - accuracy: 0.7696 - val_loss: 1.1470 - val_accuracy: 0.6188\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6518 - accuracy: 0.7764 - val_loss: 1.1342 - val_accuracy: 0.6263\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6312 - accuracy: 0.7845 - val_loss: 1.1550 - val_accuracy: 0.6229\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.6116 - accuracy: 0.7910 - val_loss: 1.1472 - val_accuracy: 0.6297\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5921 - accuracy: 0.8000 - val_loss: 1.1890 - val_accuracy: 0.6225\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5741 - accuracy: 0.8045 - val_loss: 1.1748 - val_accuracy: 0.6210\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5545 - accuracy: 0.8121 - val_loss: 1.1844 - val_accuracy: 0.6269\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5367 - accuracy: 0.8190 - val_loss: 1.2141 - val_accuracy: 0.6225\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 19s 12ms/step - loss: 0.5182 - accuracy: 0.8257 - val_loss: 1.2288 - val_accuracy: 0.6167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = build_model('full_scratch', weights=None)\n",
        "model = build_resnet50('full_scratch', weights='imagenet', optimizer='adam')\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "              batch_size=batch_size,\n",
        "              epochs=epochs,\n",
        "              validation_data=(x_test, y_test),\n",
        "              shuffle=True)\n",
        "\n",
        "model.save(r'/content/drive/MyDrive/projects/model_resnet50_imagenet', save_format='h5')\n",
        "pd.DataFrame(history.history).to_csv('/content/drive/MyDrive/projects/history_resnet50_imagenet.csv')\n"
      ],
      "metadata": {
        "id": "V5ywtNnY5Jwb",
        "outputId": "0aa36521-99ae-4c67-addf-8b661fee08d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"full_scratch\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 38, 38, 3)    0           ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 16, 16, 64)   9472        ['conv1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1_conv[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 16, 16, 64)   0           ['conv1_bn[0][0]']               \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 18, 18, 64)   0           ['conv1_relu[0][0]']             \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 8, 8, 64)     0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 64)     4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 8, 8, 256)    16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 8, 8, 256)    0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 64)     16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 64)     36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 8, 8, 64)    256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 8, 8, 256)    16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 8, 8, 256)   1024        ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 8, 8, 256)    0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 8, 8, 256)    0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 4, 4, 512)    131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 4, 4, 512)    0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 4, 4, 512)    0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 128)    147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 4, 4, 512)    66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 4, 4, 512)   2048        ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 4, 4, 512)    0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 4, 4, 512)    0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 256)    131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 2, 2, 1024)   525312      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                                                  'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block1_out[0][0]',       \n",
            "                                                                  'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block2_out[0][0]',       \n",
            "                                                                  'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block3_out[0][0]',       \n",
            "                                                                  'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block4_out[0][0]',       \n",
            "                                                                  'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block5_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 256)    262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 256)    590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 2, 2, 256)   1024        ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 2, 2, 1024)   263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 2, 2, 1024)  4096        ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 2, 2, 1024)   0           ['conv4_block5_out[0][0]',       \n",
            "                                                                  'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 2, 2, 1024)   0           ['conv4_block6_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 1, 1, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 1, 1, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 1, 1, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 1, 1, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 1, 1, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 1, 1, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 1, 1, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " global_average_pooling2d_3 (Gl  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " obalAveragePooling2D)                                                                            \n",
            "                                                                                                  \n",
            " dense_6 (Dense)                (None, 512)          1049088     ['global_average_pooling2d_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dense_7 (Dense)                (None, 512)          262656      ['dense_6[0][0]']                \n",
            "                                                                                                  \n",
            " dense_8 (Dense)                (None, 10)           5130        ['dense_7[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 24,904,586\n",
            "Trainable params: 1,316,874\n",
            "Non-trainable params: 23,587,712\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "1563/1563 [==============================] - 35s 20ms/step - loss: 2.0233 - accuracy: 0.2601 - val_loss: 1.9225 - val_accuracy: 0.2997\n",
            "Epoch 2/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.8613 - accuracy: 0.3257 - val_loss: 1.8146 - val_accuracy: 0.3357\n",
            "Epoch 3/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.8018 - accuracy: 0.3501 - val_loss: 1.7968 - val_accuracy: 0.3506\n",
            "Epoch 4/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.7604 - accuracy: 0.3660 - val_loss: 1.7422 - val_accuracy: 0.3693\n",
            "Epoch 5/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.7322 - accuracy: 0.3762 - val_loss: 1.7988 - val_accuracy: 0.3460\n",
            "Epoch 6/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.7127 - accuracy: 0.3840 - val_loss: 1.7350 - val_accuracy: 0.3756\n",
            "Epoch 7/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.6924 - accuracy: 0.3931 - val_loss: 1.6625 - val_accuracy: 0.4051\n",
            "Epoch 8/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.6768 - accuracy: 0.3987 - val_loss: 1.6593 - val_accuracy: 0.4093\n",
            "Epoch 9/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.6635 - accuracy: 0.4057 - val_loss: 1.6394 - val_accuracy: 0.4131\n",
            "Epoch 10/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.6495 - accuracy: 0.4092 - val_loss: 1.6284 - val_accuracy: 0.4178\n",
            "Epoch 11/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.6406 - accuracy: 0.4134 - val_loss: 1.6210 - val_accuracy: 0.4220\n",
            "Epoch 12/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.6338 - accuracy: 0.4151 - val_loss: 1.6309 - val_accuracy: 0.4197\n",
            "Epoch 13/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.6221 - accuracy: 0.4214 - val_loss: 1.6109 - val_accuracy: 0.4280\n",
            "Epoch 14/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.6098 - accuracy: 0.4244 - val_loss: 1.5935 - val_accuracy: 0.4302\n",
            "Epoch 15/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.6063 - accuracy: 0.4264 - val_loss: 1.6530 - val_accuracy: 0.4111\n",
            "Epoch 16/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.5976 - accuracy: 0.4304 - val_loss: 1.6427 - val_accuracy: 0.4097\n",
            "Epoch 17/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.5923 - accuracy: 0.4335 - val_loss: 1.5803 - val_accuracy: 0.4329\n",
            "Epoch 18/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.5803 - accuracy: 0.4376 - val_loss: 1.5774 - val_accuracy: 0.4411\n",
            "Epoch 19/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.5760 - accuracy: 0.4376 - val_loss: 1.5876 - val_accuracy: 0.4252\n",
            "Epoch 20/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.5646 - accuracy: 0.4419 - val_loss: 1.5702 - val_accuracy: 0.4423\n",
            "Epoch 21/30\n",
            "1563/1563 [==============================] - 32s 20ms/step - loss: 1.5628 - accuracy: 0.4435 - val_loss: 1.5645 - val_accuracy: 0.4444\n",
            "Epoch 22/30\n",
            "1563/1563 [==============================] - 30s 20ms/step - loss: 1.5600 - accuracy: 0.4452 - val_loss: 1.5564 - val_accuracy: 0.4473\n",
            "Epoch 23/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.5544 - accuracy: 0.4474 - val_loss: 1.6058 - val_accuracy: 0.4276\n",
            "Epoch 24/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.5447 - accuracy: 0.4511 - val_loss: 1.5740 - val_accuracy: 0.4425\n",
            "Epoch 25/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.5374 - accuracy: 0.4532 - val_loss: 1.5445 - val_accuracy: 0.4545\n",
            "Epoch 26/30\n",
            "1563/1563 [==============================] - 32s 21ms/step - loss: 1.5352 - accuracy: 0.4538 - val_loss: 1.5575 - val_accuracy: 0.4433\n",
            "Epoch 27/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.5274 - accuracy: 0.4589 - val_loss: 1.5305 - val_accuracy: 0.4616\n",
            "Epoch 28/30\n",
            "1563/1563 [==============================] - 30s 19ms/step - loss: 1.5193 - accuracy: 0.4597 - val_loss: 1.5226 - val_accuracy: 0.4581\n",
            "Epoch 29/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.5190 - accuracy: 0.4627 - val_loss: 1.6818 - val_accuracy: 0.4059\n",
            "Epoch 30/30\n",
            "1563/1563 [==============================] - 31s 20ms/step - loss: 1.5129 - accuracy: 0.4625 - val_loss: 1.5981 - val_accuracy: 0.4316\n"
          ]
        }
      ]
    }
  ]
}