{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cifar10_from_softmax_to_transfer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/borislevant/CourseraMachineLearning/blob/master/cifar10_from_softmax_to_transfer.ipynb",
      "authorship_tag": "ABX9TyNpb793GLM8+3MF54WGE2Sb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/borislevant/SciComPy/blob/master/cifar10_optuna_package.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will demonstrate the work on the CIFAR-10 data set from the simplest Softmax model (Logistic regression) to the more advanced methods"
      ],
      "metadata": {
        "id": "7dy5Gp7sziul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Introduction\n",
        "The CIFAR-10 dataset contains 60,000 color images of 32 x 32 pixels in 3 channels divided into 10\n",
        "classes. Each class contains 6,000 images. The training set contains 50,000 images, while the test sets\n",
        "provides 10,000 images. This image taken from the CIFAR repository ( <a href = \"https://www.cs.toronto.edu/~kriz/cifar.html\">https://www.cs.toronto.edu/~kriz/cifar.html </a>). This is a classification problem with 10 classes(muti-label classification). We can take a view on this image for more comprehension of the dataset. \n",
        "\n",
        "![cifar10.png](https://github.com/borislevant/SciComPy/blob/master/cifar10.png?raw=1)\n",
        "\n",
        "\n",
        "The challenge is to recognize previously unseen images and assign them to one of the 10 classes.\n",
        "\n",
        "Ok Let's get started."
      ],
      "metadata": {
        "id": "ODkXzxzJX4RV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Import and Preprocess the data\n",
        "\n"
      ],
      "metadata": {
        "id": "8loO1ZCAYNFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1 Import all required libraries"
      ],
      "metadata": {
        "id": "CQEVEyzgcsQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from tensorflow import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, InputLayer\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import itertools\n",
        "\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "RxZygPoMYOJi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n",
        "import optuna\n",
        "from optuna.integration import KerasPruningCallback\n",
        "from optuna.trial import TrialState"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyAvqZ3BU334",
        "outputId": "2a9e6b3c-f23f-4aeb-8ade-c4529d386141"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting optuna\n",
            "  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
            "\u001b[K     |████████████████████████████████| 308 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.39)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 4.8 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.8.1-py3-none-any.whl (209 kB)\n",
            "\u001b[K     |████████████████████████████████| 209 kB 42.1 MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.12.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.8.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 4.2 MB/s \n",
            "\u001b[?25hCollecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.2-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 55.5 MB/s \n",
            "\u001b[?25hCollecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
            "Collecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 24.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=ec72a3e1da6a11e105a1e20b5a223243f30302c275c18b7f5197ac11e49a1d45\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.2.1 alembic-1.8.1 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.2 colorlog-6.6.0 optuna-2.10.1 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2 Import and preproces of data \n",
        "We load the data and split it between train and test sets\n"
      ],
      "metadata": {
        "id": "od0ht3ORYW_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The data, split between train and test sets:\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vQGeMoaYZeP",
        "outputId": "0b2c118a-eac6-49d1-9a41-e0420a23b7f4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n",
            "x_train shape: (50000, 32, 32, 3)\n",
            "y_train shape: (50000, 1)\n",
            "50000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data. Before we need to connvert data type to float for computation.\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices. This is called one hot encoding.\n",
        "num_classes = 10  # Number of class for the dataset\n",
        "num_epochs = 20\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "metadata": {
        "id": "bMdzujJVcfoI"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Softmax model"
      ],
      "metadata": {
        "id": "vJ6g0nKpaVf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_softmax_model(trial):\n",
        "    l2_regularization=trial.suggest_float(\"l2_regularization\", 1e-5, 1e-1, log=True)\n",
        "    reg = keras.regularizers.l2(l2=l2_regularization)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=x_train.shape[1:]))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=reg))\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def accuracy_softmax_mode(trial):\n",
        "    learning_rate=trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model = create_softmax_model(trial)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    batch_size = trial.suggest_int(\"batch_size\", 2, 256, log=True)\n",
        "    history = model.fit(x_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=num_epochs,\n",
        "                validation_data=(x_test, y_test),\n",
        "                shuffle=True)\n",
        "\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return score[1]\n"
      ],
      "metadata": {
        "id": "eHHh5oltaVDa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3.1 Optimizing the Softmax model"
      ],
      "metadata": {
        "id": "Ptd9DvO7NSVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(accuracy_softmax_mode, n_trials=20)\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n",
        "\n"
      ],
      "metadata": {
        "id": "Q1nImjQpciHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3ac30c-9e19-4c51-f37f-2facfc6b6403"
      },
      "execution_count": 7,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-21 06:19:59,008]\u001b[0m A new study created in memory with name: no-name-f563b791-124b-4bfd-a491-d32a9a024347\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 3072)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "313/313 [==============================] - 5s 5ms/step - loss: 2.9121 - accuracy: 0.2827 - val_loss: 2.0883 - val_accuracy: 0.3174\n",
            "Epoch 2/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2608 - accuracy: 0.3067 - val_loss: 2.0902 - val_accuracy: 0.3165\n",
            "Epoch 3/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2046 - accuracy: 0.3190 - val_loss: 2.0124 - val_accuracy: 0.3357\n",
            "Epoch 4/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1306 - accuracy: 0.3333 - val_loss: 2.4623 - val_accuracy: 0.3100\n",
            "Epoch 5/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2009 - accuracy: 0.3303 - val_loss: 2.3273 - val_accuracy: 0.2998\n",
            "Epoch 6/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2869 - accuracy: 0.3275 - val_loss: 3.1055 - val_accuracy: 0.3136\n",
            "Epoch 7/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1998 - accuracy: 0.3386 - val_loss: 2.7294 - val_accuracy: 0.2321\n",
            "Epoch 8/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1378 - accuracy: 0.3414 - val_loss: 2.3528 - val_accuracy: 0.3295\n",
            "Epoch 9/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2121 - accuracy: 0.3341 - val_loss: 2.5371 - val_accuracy: 0.2935\n",
            "Epoch 10/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1916 - accuracy: 0.3369 - val_loss: 2.2964 - val_accuracy: 0.3210\n",
            "Epoch 11/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1044 - accuracy: 0.3480 - val_loss: 2.0655 - val_accuracy: 0.3657\n",
            "Epoch 12/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2163 - accuracy: 0.3393 - val_loss: 2.8411 - val_accuracy: 0.2478\n",
            "Epoch 13/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.0433 - accuracy: 0.3599 - val_loss: 2.0047 - val_accuracy: 0.3553\n",
            "Epoch 14/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.3053 - accuracy: 0.3325 - val_loss: 2.3449 - val_accuracy: 0.2829\n",
            "Epoch 15/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2407 - accuracy: 0.3366 - val_loss: 2.4441 - val_accuracy: 0.2825\n",
            "Epoch 16/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.0715 - accuracy: 0.3529 - val_loss: 1.8677 - val_accuracy: 0.3720\n",
            "Epoch 17/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.2128 - accuracy: 0.3451 - val_loss: 2.2088 - val_accuracy: 0.3334\n",
            "Epoch 18/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1050 - accuracy: 0.3558 - val_loss: 2.7754 - val_accuracy: 0.3435\n",
            "Epoch 19/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.1105 - accuracy: 0.3520 - val_loss: 2.0000 - val_accuracy: 0.3391\n",
            "Epoch 20/20\n",
            "313/313 [==============================] - 1s 4ms/step - loss: 2.3768 - accuracy: 0.3376 - val_loss: 2.0310 - val_accuracy: 0.3708\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-21 06:20:33,678]\u001b[0m Trial 0 finished with value: 0.3707999885082245 and parameters: {'learning_rate': 0.008796923289167547, 'l2_regularization': 0.0002295533555353467, 'batch_size': 160}. Best is trial 0 with value: 0.3707999885082245.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 2.0090 - accuracy: 0.2881 - val_loss: 1.9066 - val_accuracy: 0.3315\n",
            "Epoch 2/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.8680 - accuracy: 0.3472 - val_loss: 1.8478 - val_accuracy: 0.3555\n",
            "Epoch 3/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.8305 - accuracy: 0.3666 - val_loss: 1.8179 - val_accuracy: 0.3663\n",
            "Epoch 4/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.8088 - accuracy: 0.3757 - val_loss: 1.8061 - val_accuracy: 0.3756\n",
            "Epoch 5/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7929 - accuracy: 0.3809 - val_loss: 1.7935 - val_accuracy: 0.3807\n",
            "Epoch 6/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7823 - accuracy: 0.3863 - val_loss: 1.7849 - val_accuracy: 0.3826\n",
            "Epoch 7/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7728 - accuracy: 0.3895 - val_loss: 1.7815 - val_accuracy: 0.3881\n",
            "Epoch 8/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7661 - accuracy: 0.3923 - val_loss: 1.7663 - val_accuracy: 0.3942\n",
            "Epoch 9/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7599 - accuracy: 0.3961 - val_loss: 1.7742 - val_accuracy: 0.3886\n",
            "Epoch 10/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7529 - accuracy: 0.4009 - val_loss: 1.7645 - val_accuracy: 0.3959\n",
            "Epoch 11/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7485 - accuracy: 0.3996 - val_loss: 1.7590 - val_accuracy: 0.3957\n",
            "Epoch 12/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7443 - accuracy: 0.4029 - val_loss: 1.7643 - val_accuracy: 0.3904\n",
            "Epoch 13/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7402 - accuracy: 0.4050 - val_loss: 1.7668 - val_accuracy: 0.3848\n",
            "Epoch 14/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7367 - accuracy: 0.4058 - val_loss: 1.7526 - val_accuracy: 0.3936\n",
            "Epoch 15/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7337 - accuracy: 0.4067 - val_loss: 1.7522 - val_accuracy: 0.3965\n",
            "Epoch 16/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7305 - accuracy: 0.4091 - val_loss: 1.7509 - val_accuracy: 0.3899\n",
            "Epoch 17/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7273 - accuracy: 0.4098 - val_loss: 1.7551 - val_accuracy: 0.3964\n",
            "Epoch 18/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7244 - accuracy: 0.4106 - val_loss: 1.7538 - val_accuracy: 0.3976\n",
            "Epoch 19/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7221 - accuracy: 0.4115 - val_loss: 1.7431 - val_accuracy: 0.3937\n",
            "Epoch 20/20\n",
            "1316/1316 [==============================] - 4s 3ms/step - loss: 1.7198 - accuracy: 0.4147 - val_loss: 1.7470 - val_accuracy: 0.3932\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-21 06:21:55,507]\u001b[0m Trial 1 finished with value: 0.39320001006126404 and parameters: {'learning_rate': 8.147597797408284e-05, 'l2_regularization': 0.00019598099775838747, 'batch_size': 38}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_2 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "794/794 [==============================] - 3s 3ms/step - loss: 2.7361 - accuracy: 0.2929 - val_loss: 2.3725 - val_accuracy: 0.3362\n",
            "Epoch 2/20\n",
            "794/794 [==============================] - 3s 3ms/step - loss: 2.2178 - accuracy: 0.3460 - val_loss: 2.1020 - val_accuracy: 0.3506\n",
            "Epoch 3/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 2.0433 - accuracy: 0.3558 - val_loss: 2.0078 - val_accuracy: 0.3420\n",
            "Epoch 4/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9771 - accuracy: 0.3619 - val_loss: 1.9707 - val_accuracy: 0.3539\n",
            "Epoch 5/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9553 - accuracy: 0.3584 - val_loss: 1.9483 - val_accuracy: 0.3558\n",
            "Epoch 6/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9450 - accuracy: 0.3602 - val_loss: 1.9506 - val_accuracy: 0.3617\n",
            "Epoch 7/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9412 - accuracy: 0.3631 - val_loss: 1.9371 - val_accuracy: 0.3602\n",
            "Epoch 8/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9403 - accuracy: 0.3642 - val_loss: 1.9432 - val_accuracy: 0.3562\n",
            "Epoch 9/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9385 - accuracy: 0.3638 - val_loss: 1.9431 - val_accuracy: 0.3651\n",
            "Epoch 10/20\n",
            "794/794 [==============================] - 3s 3ms/step - loss: 1.9399 - accuracy: 0.3635 - val_loss: 1.9400 - val_accuracy: 0.3599\n",
            "Epoch 11/20\n",
            "794/794 [==============================] - 3s 3ms/step - loss: 1.9381 - accuracy: 0.3646 - val_loss: 1.9300 - val_accuracy: 0.3731\n",
            "Epoch 12/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9379 - accuracy: 0.3644 - val_loss: 1.9346 - val_accuracy: 0.3726\n",
            "Epoch 13/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9376 - accuracy: 0.3636 - val_loss: 1.9423 - val_accuracy: 0.3661\n",
            "Epoch 14/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9361 - accuracy: 0.3664 - val_loss: 1.9422 - val_accuracy: 0.3582\n",
            "Epoch 15/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9364 - accuracy: 0.3666 - val_loss: 1.9469 - val_accuracy: 0.3537\n",
            "Epoch 16/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9364 - accuracy: 0.3642 - val_loss: 1.9341 - val_accuracy: 0.3696\n",
            "Epoch 17/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9356 - accuracy: 0.3662 - val_loss: 1.9367 - val_accuracy: 0.3613\n",
            "Epoch 18/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9361 - accuracy: 0.3644 - val_loss: 1.9360 - val_accuracy: 0.3720\n",
            "Epoch 19/20\n",
            "794/794 [==============================] - 3s 3ms/step - loss: 1.9353 - accuracy: 0.3667 - val_loss: 1.9332 - val_accuracy: 0.3689\n",
            "Epoch 20/20\n",
            "794/794 [==============================] - 2s 3ms/step - loss: 1.9341 - accuracy: 0.3675 - val_loss: 1.9357 - val_accuracy: 0.3605\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-21 06:23:19,583]\u001b[0m Trial 2 finished with value: 0.3605000078678131 and parameters: {'learning_rate': 0.00011562325988733797, 'l2_regularization': 0.054385642969273514, 'batch_size': 63}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_3 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.2199 - accuracy: 0.2928 - val_loss: 2.0472 - val_accuracy: 0.3003\n",
            "Epoch 2/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0662 - accuracy: 0.3031 - val_loss: 2.0315 - val_accuracy: 0.3084\n",
            "Epoch 3/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0706 - accuracy: 0.3012 - val_loss: 1.9603 - val_accuracy: 0.3497\n",
            "Epoch 4/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0592 - accuracy: 0.3049 - val_loss: 2.0385 - val_accuracy: 0.3238\n",
            "Epoch 5/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0568 - accuracy: 0.3058 - val_loss: 1.9886 - val_accuracy: 0.3303\n",
            "Epoch 6/20\n",
            "2273/2273 [==============================] - 6s 3ms/step - loss: 2.0561 - accuracy: 0.3072 - val_loss: 2.0203 - val_accuracy: 0.3067\n",
            "Epoch 7/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0615 - accuracy: 0.3018 - val_loss: 1.9847 - val_accuracy: 0.3243\n",
            "Epoch 8/20\n",
            "2273/2273 [==============================] - 6s 3ms/step - loss: 2.0561 - accuracy: 0.3084 - val_loss: 2.0420 - val_accuracy: 0.3086\n",
            "Epoch 9/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0543 - accuracy: 0.3086 - val_loss: 2.1905 - val_accuracy: 0.2868\n",
            "Epoch 10/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0550 - accuracy: 0.3054 - val_loss: 2.0313 - val_accuracy: 0.3057\n",
            "Epoch 11/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0470 - accuracy: 0.3109 - val_loss: 2.0095 - val_accuracy: 0.3081\n",
            "Epoch 12/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0501 - accuracy: 0.3098 - val_loss: 1.9643 - val_accuracy: 0.3433\n",
            "Epoch 13/20\n",
            "2273/2273 [==============================] - 6s 3ms/step - loss: 2.0555 - accuracy: 0.3057 - val_loss: 2.0597 - val_accuracy: 0.2896\n",
            "Epoch 14/20\n",
            "2273/2273 [==============================] - 6s 3ms/step - loss: 2.0557 - accuracy: 0.3080 - val_loss: 2.1076 - val_accuracy: 0.2734\n",
            "Epoch 15/20\n",
            "2273/2273 [==============================] - 6s 3ms/step - loss: 2.0445 - accuracy: 0.3106 - val_loss: 2.0688 - val_accuracy: 0.3025\n",
            "Epoch 16/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0510 - accuracy: 0.3087 - val_loss: 2.0442 - val_accuracy: 0.3026\n",
            "Epoch 17/20\n",
            "2273/2273 [==============================] - 6s 3ms/step - loss: 2.0515 - accuracy: 0.3095 - val_loss: 2.0206 - val_accuracy: 0.3099\n",
            "Epoch 18/20\n",
            "2273/2273 [==============================] - 6s 3ms/step - loss: 2.0527 - accuracy: 0.3094 - val_loss: 2.0611 - val_accuracy: 0.2866\n",
            "Epoch 19/20\n",
            "2273/2273 [==============================] - 7s 3ms/step - loss: 2.0501 - accuracy: 0.3089 - val_loss: 1.9949 - val_accuracy: 0.3377\n",
            "Epoch 20/20\n",
            "2273/2273 [==============================] - 6s 3ms/step - loss: 2.0454 - accuracy: 0.3100 - val_loss: 2.1347 - val_accuracy: 0.2635\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-21 06:25:34,850]\u001b[0m Trial 3 finished with value: 0.26350000500679016 and parameters: {'learning_rate': 0.0006262370917930784, 'l2_regularization': 0.057222727279621584, 'batch_size': 22}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_4 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "807/807 [==============================] - 3s 3ms/step - loss: 1.9639 - accuracy: 0.3150 - val_loss: 1.9073 - val_accuracy: 0.3340\n",
            "Epoch 2/20\n",
            "807/807 [==============================] - 3s 3ms/step - loss: 1.8617 - accuracy: 0.3564 - val_loss: 1.8222 - val_accuracy: 0.3589\n",
            "Epoch 3/20\n",
            "807/807 [==============================] - 3s 3ms/step - loss: 1.8496 - accuracy: 0.3635 - val_loss: 1.8944 - val_accuracy: 0.3506\n",
            "Epoch 4/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.8284 - accuracy: 0.3712 - val_loss: 1.9038 - val_accuracy: 0.3421\n",
            "Epoch 5/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.8314 - accuracy: 0.3750 - val_loss: 1.8957 - val_accuracy: 0.3502\n",
            "Epoch 6/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.8183 - accuracy: 0.3786 - val_loss: 1.9080 - val_accuracy: 0.3469\n",
            "Epoch 7/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.8136 - accuracy: 0.3805 - val_loss: 1.8113 - val_accuracy: 0.3744\n",
            "Epoch 8/20\n",
            "807/807 [==============================] - 3s 4ms/step - loss: 1.8129 - accuracy: 0.3865 - val_loss: 1.8702 - val_accuracy: 0.3673\n",
            "Epoch 9/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.7960 - accuracy: 0.3888 - val_loss: 1.8075 - val_accuracy: 0.3823\n",
            "Epoch 10/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.7983 - accuracy: 0.3855 - val_loss: 1.8568 - val_accuracy: 0.3694\n",
            "Epoch 11/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.7940 - accuracy: 0.3921 - val_loss: 1.8531 - val_accuracy: 0.3619\n",
            "Epoch 12/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.7957 - accuracy: 0.3904 - val_loss: 1.9253 - val_accuracy: 0.3544\n",
            "Epoch 13/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.7933 - accuracy: 0.3908 - val_loss: 1.8032 - val_accuracy: 0.3755\n",
            "Epoch 14/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.7946 - accuracy: 0.3956 - val_loss: 1.8926 - val_accuracy: 0.3615\n",
            "Epoch 15/20\n",
            "807/807 [==============================] - 3s 3ms/step - loss: 1.7883 - accuracy: 0.3940 - val_loss: 1.8621 - val_accuracy: 0.3542\n",
            "Epoch 16/20\n",
            "807/807 [==============================] - 3s 3ms/step - loss: 1.7861 - accuracy: 0.3965 - val_loss: 1.8113 - val_accuracy: 0.3788\n",
            "Epoch 17/20\n",
            "807/807 [==============================] - 3s 3ms/step - loss: 1.7787 - accuracy: 0.3972 - val_loss: 1.8896 - val_accuracy: 0.3463\n",
            "Epoch 18/20\n",
            "807/807 [==============================] - 2s 3ms/step - loss: 1.7946 - accuracy: 0.3927 - val_loss: 1.8092 - val_accuracy: 0.3778\n",
            "Epoch 19/20\n",
            "807/807 [==============================] - 3s 3ms/step - loss: 1.7856 - accuracy: 0.3963 - val_loss: 1.9973 - val_accuracy: 0.3220\n",
            "Epoch 20/20\n",
            "807/807 [==============================] - 3s 3ms/step - loss: 1.7926 - accuracy: 0.3931 - val_loss: 1.7815 - val_accuracy: 0.3930\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-21 06:26:28,786]\u001b[0m Trial 4 finished with value: 0.3930000066757202 and parameters: {'learning_rate': 0.0012700212681924143, 'l2_regularization': 0.00037031914721331655, 'batch_size': 62}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 2.0175 - accuracy: 0.3132 - val_loss: 1.9249 - val_accuracy: 0.3663\n",
            "Epoch 2/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.9060 - accuracy: 0.3623 - val_loss: 1.8636 - val_accuracy: 0.3770\n",
            "Epoch 3/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8723 - accuracy: 0.3726 - val_loss: 1.8452 - val_accuracy: 0.3886\n",
            "Epoch 4/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8522 - accuracy: 0.3811 - val_loss: 1.8395 - val_accuracy: 0.3821\n",
            "Epoch 5/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8351 - accuracy: 0.3854 - val_loss: 1.8566 - val_accuracy: 0.3649\n",
            "Epoch 6/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8267 - accuracy: 0.3869 - val_loss: 1.8332 - val_accuracy: 0.3837\n",
            "Epoch 7/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8192 - accuracy: 0.3890 - val_loss: 1.8525 - val_accuracy: 0.3750\n",
            "Epoch 8/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8143 - accuracy: 0.3919 - val_loss: 1.8105 - val_accuracy: 0.3958\n",
            "Epoch 9/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8098 - accuracy: 0.3932 - val_loss: 1.8469 - val_accuracy: 0.3640\n",
            "Epoch 10/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8081 - accuracy: 0.3926 - val_loss: 1.8099 - val_accuracy: 0.3868\n",
            "Epoch 11/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8060 - accuracy: 0.3912 - val_loss: 1.7985 - val_accuracy: 0.3984\n",
            "Epoch 12/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.8035 - accuracy: 0.3962 - val_loss: 1.8027 - val_accuracy: 0.3944\n",
            "Epoch 13/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.7994 - accuracy: 0.3944 - val_loss: 1.8043 - val_accuracy: 0.3908\n",
            "Epoch 14/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.7971 - accuracy: 0.3968 - val_loss: 1.8214 - val_accuracy: 0.3783\n",
            "Epoch 15/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.7942 - accuracy: 0.4003 - val_loss: 1.7936 - val_accuracy: 0.4003\n",
            "Epoch 16/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.7960 - accuracy: 0.3976 - val_loss: 1.8108 - val_accuracy: 0.3891\n",
            "Epoch 17/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.7937 - accuracy: 0.3982 - val_loss: 1.8198 - val_accuracy: 0.3853\n",
            "Epoch 18/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.7932 - accuracy: 0.3959 - val_loss: 1.8086 - val_accuracy: 0.3915\n",
            "Epoch 19/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.7932 - accuracy: 0.3996 - val_loss: 1.7855 - val_accuracy: 0.4033\n",
            "Epoch 20/20\n",
            "1613/1613 [==============================] - 5s 3ms/step - loss: 1.7927 - accuracy: 0.3975 - val_loss: 1.8102 - val_accuracy: 0.3902\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-21 06:28:04,025]\u001b[0m Trial 5 finished with value: 0.3901999890804291 and parameters: {'learning_rate': 0.000225245362987259, 'l2_regularization': 0.0044721699687196356, 'batch_size': 31}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_6 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5000/5000 [==============================] - 14s 3ms/step - loss: 2.1083 - accuracy: 0.3054 - val_loss: 2.0018 - val_accuracy: 0.3233\n",
            "Epoch 2/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0277 - accuracy: 0.3284 - val_loss: 1.9655 - val_accuracy: 0.3262\n",
            "Epoch 3/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0157 - accuracy: 0.3319 - val_loss: 1.9923 - val_accuracy: 0.3272\n",
            "Epoch 4/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0067 - accuracy: 0.3327 - val_loss: 1.9930 - val_accuracy: 0.3374\n",
            "Epoch 5/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0054 - accuracy: 0.3347 - val_loss: 1.9846 - val_accuracy: 0.3351\n",
            "Epoch 6/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0066 - accuracy: 0.3359 - val_loss: 2.0292 - val_accuracy: 0.3358\n",
            "Epoch 7/20\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 2.0058 - accuracy: 0.3366 - val_loss: 1.9659 - val_accuracy: 0.3386\n",
            "Epoch 8/20\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 1.9946 - accuracy: 0.3371 - val_loss: 2.0425 - val_accuracy: 0.3089\n",
            "Epoch 9/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0005 - accuracy: 0.3384 - val_loss: 1.9666 - val_accuracy: 0.3391\n",
            "Epoch 10/20\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 2.0057 - accuracy: 0.3344 - val_loss: 2.1361 - val_accuracy: 0.3118\n",
            "Epoch 11/20\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 2.0020 - accuracy: 0.3352 - val_loss: 2.0610 - val_accuracy: 0.3023\n",
            "Epoch 12/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0084 - accuracy: 0.3358 - val_loss: 2.2868 - val_accuracy: 0.2659\n",
            "Epoch 13/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0038 - accuracy: 0.3383 - val_loss: 2.1553 - val_accuracy: 0.3060\n",
            "Epoch 14/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 1.9948 - accuracy: 0.3396 - val_loss: 2.1176 - val_accuracy: 0.2994\n",
            "Epoch 15/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 1.9980 - accuracy: 0.3378 - val_loss: 1.9347 - val_accuracy: 0.3507\n",
            "Epoch 16/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 2.0023 - accuracy: 0.3379 - val_loss: 2.0483 - val_accuracy: 0.3418\n",
            "Epoch 17/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 1.9984 - accuracy: 0.3377 - val_loss: 1.9869 - val_accuracy: 0.3422\n",
            "Epoch 18/20\n",
            "5000/5000 [==============================] - 12s 2ms/step - loss: 2.0047 - accuracy: 0.3374 - val_loss: 2.0617 - val_accuracy: 0.3336\n",
            "Epoch 19/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 1.9958 - accuracy: 0.3392 - val_loss: 2.0338 - val_accuracy: 0.3280\n",
            "Epoch 20/20\n",
            "5000/5000 [==============================] - 13s 3ms/step - loss: 1.9964 - accuracy: 0.3402 - val_loss: 1.8990 - val_accuracy: 0.3703\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-07-21 06:32:28,208]\u001b[0m Trial 6 finished with value: 0.3702999949455261 and parameters: {'learning_rate': 0.0006943325184470356, 'l2_regularization': 0.00576841029099181, 'batch_size': 10}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "25000/25000 [==============================] - 61s 2ms/step - loss: 51.7537 - accuracy: 0.1995 - val_loss: 60.0271 - val_accuracy: 0.1510\n",
            "Epoch 2/20\n",
            "25000/25000 [==============================] - 58s 2ms/step - loss: 52.5956 - accuracy: 0.2031 - val_loss: 34.8892 - val_accuracy: 0.2388\n",
            "Epoch 3/20\n",
            "25000/25000 [==============================] - 61s 2ms/step - loss: 52.1004 - accuracy: 0.2008 - val_loss: 53.2122 - val_accuracy: 0.2085\n",
            "Epoch 4/20\n",
            "25000/25000 [==============================] - 58s 2ms/step - loss: 52.1407 - accuracy: 0.2063 - val_loss: 52.3662 - val_accuracy: 0.2299\n",
            "Epoch 5/20\n",
            "25000/25000 [==============================] - 61s 2ms/step - loss: 51.5223 - accuracy: 0.2050 - val_loss: 50.2489 - val_accuracy: 0.1719\n",
            "Epoch 6/20\n",
            "25000/25000 [==============================] - 61s 2ms/step - loss: 52.2639 - accuracy: 0.2037 - val_loss: 78.7485 - val_accuracy: 0.1931\n",
            "Epoch 7/20\n",
            "25000/25000 [==============================] - 57s 2ms/step - loss: 52.4994 - accuracy: 0.2025 - val_loss: 35.7662 - val_accuracy: 0.2529\n",
            "Epoch 8/20\n",
            "25000/25000 [==============================] - 57s 2ms/step - loss: 52.1854 - accuracy: 0.2019 - val_loss: 62.7716 - val_accuracy: 0.2064\n",
            "Epoch 9/20\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 52.0743 - accuracy: 0.2057 - val_loss: 63.5112 - val_accuracy: 0.2096\n",
            "Epoch 10/20\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 51.9531 - accuracy: 0.2050 - val_loss: 49.3567 - val_accuracy: 0.1681\n",
            "Epoch 11/20\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 51.9783 - accuracy: 0.2057 - val_loss: 55.7746 - val_accuracy: 0.2101\n",
            "Epoch 12/20\n",
            "25000/25000 [==============================] - 59s 2ms/step - loss: 52.2173 - accuracy: 0.2022 - val_loss: 56.7605 - val_accuracy: 0.1991\n",
            "Epoch 13/20\n",
            "25000/25000 [==============================] - 59s 2ms/step - loss: 52.0677 - accuracy: 0.2081 - val_loss: 69.9836 - val_accuracy: 0.1770\n",
            "Epoch 14/20\n",
            "25000/25000 [==============================] - 56s 2ms/step - loss: 51.5586 - accuracy: 0.2056 - val_loss: 47.7519 - val_accuracy: 0.1842\n",
            "Epoch 15/20\n",
            "25000/25000 [==============================] - 59s 2ms/step - loss: 52.7967 - accuracy: 0.2057 - val_loss: 51.4219 - val_accuracy: 0.2134\n",
            "Epoch 16/20\n",
            "25000/25000 [==============================] - 60s 2ms/step - loss: 52.5641 - accuracy: 0.2062 - val_loss: 48.9986 - val_accuracy: 0.1927\n",
            "Epoch 17/20\n",
            "25000/25000 [==============================] - 61s 2ms/step - loss: 52.3624 - accuracy: 0.2058 - val_loss: 49.2799 - val_accuracy: 0.1904\n",
            "Epoch 18/20\n",
            "25000/25000 [==============================] - 57s 2ms/step - loss: 52.3231 - accuracy: 0.2043 - val_loss: 45.2392 - val_accuracy: 0.2367\n",
            "Epoch 19/20\n",
            "25000/25000 [==============================] - 61s 2ms/step - loss: 52.2139 - accuracy: 0.2065 - val_loss: 67.5671 - val_accuracy: 0.2042\n",
            "Epoch 20/20\n",
            "25000/25000 [==============================] - 61s 2ms/step - loss: 52.1514 - accuracy: 0.2045 - val_loss: 60.4320 - val_accuracy: 0.2144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 06:52:52,435]\u001b[0m Trial 7 finished with value: 0.21439999341964722 and parameters: {'learning_rate': 0.02971209848034387, 'l2_regularization': 0.001924690862284383, 'batch_size': 2}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_8 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.3530 - accuracy: 0.2657 - val_loss: 3.0793 - val_accuracy: 0.2754\n",
            "Epoch 2/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.3287 - accuracy: 0.2859 - val_loss: 3.8277 - val_accuracy: 0.2350\n",
            "Epoch 3/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.2753 - accuracy: 0.2908 - val_loss: 2.9074 - val_accuracy: 0.3091\n",
            "Epoch 4/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.3023 - accuracy: 0.2902 - val_loss: 3.4199 - val_accuracy: 0.2507\n",
            "Epoch 5/20\n",
            "12500/12500 [==============================] - 30s 2ms/step - loss: 3.2997 - accuracy: 0.2893 - val_loss: 3.8436 - val_accuracy: 0.2436\n",
            "Epoch 6/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.3158 - accuracy: 0.2913 - val_loss: 3.7011 - val_accuracy: 0.3128\n",
            "Epoch 7/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.2988 - accuracy: 0.2938 - val_loss: 3.1609 - val_accuracy: 0.3125\n",
            "Epoch 8/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.2840 - accuracy: 0.2922 - val_loss: 4.6304 - val_accuracy: 0.2988\n",
            "Epoch 9/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.2941 - accuracy: 0.2916 - val_loss: 2.8667 - val_accuracy: 0.3115\n",
            "Epoch 10/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.3191 - accuracy: 0.2956 - val_loss: 4.2662 - val_accuracy: 0.2643\n",
            "Epoch 11/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.3690 - accuracy: 0.2929 - val_loss: 3.2047 - val_accuracy: 0.2709\n",
            "Epoch 12/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.3172 - accuracy: 0.2936 - val_loss: 3.8423 - val_accuracy: 0.2353\n",
            "Epoch 13/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.3246 - accuracy: 0.2901 - val_loss: 2.3338 - val_accuracy: 0.3305\n",
            "Epoch 14/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.3163 - accuracy: 0.2951 - val_loss: 2.8773 - val_accuracy: 0.2873\n",
            "Epoch 15/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.2945 - accuracy: 0.2941 - val_loss: 2.7604 - val_accuracy: 0.3147\n",
            "Epoch 16/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.3562 - accuracy: 0.2924 - val_loss: 3.7499 - val_accuracy: 0.2807\n",
            "Epoch 17/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.3386 - accuracy: 0.2936 - val_loss: 3.8201 - val_accuracy: 0.2793\n",
            "Epoch 18/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.3393 - accuracy: 0.2940 - val_loss: 2.7087 - val_accuracy: 0.2934\n",
            "Epoch 19/20\n",
            "12500/12500 [==============================] - 31s 2ms/step - loss: 3.3279 - accuracy: 0.2909 - val_loss: 4.1136 - val_accuracy: 0.2310\n",
            "Epoch 20/20\n",
            "12500/12500 [==============================] - 29s 2ms/step - loss: 3.3228 - accuracy: 0.2914 - val_loss: 3.7519 - val_accuracy: 0.2570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:03:16,598]\u001b[0m Trial 8 finished with value: 0.25699999928474426 and parameters: {'learning_rate': 0.0022732216270664363, 'l2_regularization': 0.0005685075280486903, 'batch_size': 4}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_9 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.2142 - accuracy: 0.2982 - val_loss: 2.0848 - val_accuracy: 0.3294\n",
            "Epoch 2/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.1495 - accuracy: 0.3246 - val_loss: 2.0073 - val_accuracy: 0.3487\n",
            "Epoch 3/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.1298 - accuracy: 0.3324 - val_loss: 2.3493 - val_accuracy: 0.3021\n",
            "Epoch 4/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.1234 - accuracy: 0.3358 - val_loss: 1.9602 - val_accuracy: 0.3445\n",
            "Epoch 5/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0964 - accuracy: 0.3417 - val_loss: 2.0650 - val_accuracy: 0.3351\n",
            "Epoch 6/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0953 - accuracy: 0.3449 - val_loss: 1.9640 - val_accuracy: 0.3643\n",
            "Epoch 7/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0656 - accuracy: 0.3519 - val_loss: 2.0748 - val_accuracy: 0.3387\n",
            "Epoch 8/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0734 - accuracy: 0.3518 - val_loss: 1.9826 - val_accuracy: 0.3503\n",
            "Epoch 9/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0732 - accuracy: 0.3534 - val_loss: 2.0088 - val_accuracy: 0.3492\n",
            "Epoch 10/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0774 - accuracy: 0.3530 - val_loss: 2.0921 - val_accuracy: 0.3326\n",
            "Epoch 11/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0718 - accuracy: 0.3569 - val_loss: 2.3468 - val_accuracy: 0.3006\n",
            "Epoch 12/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0559 - accuracy: 0.3576 - val_loss: 2.1275 - val_accuracy: 0.3202\n",
            "Epoch 13/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0940 - accuracy: 0.3561 - val_loss: 2.0183 - val_accuracy: 0.3415\n",
            "Epoch 14/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0577 - accuracy: 0.3564 - val_loss: 2.5892 - val_accuracy: 0.2991\n",
            "Epoch 15/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0876 - accuracy: 0.3575 - val_loss: 2.0147 - val_accuracy: 0.3559\n",
            "Epoch 16/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0555 - accuracy: 0.3624 - val_loss: 2.0884 - val_accuracy: 0.3246\n",
            "Epoch 17/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0412 - accuracy: 0.3623 - val_loss: 2.2546 - val_accuracy: 0.3069\n",
            "Epoch 18/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0481 - accuracy: 0.3592 - val_loss: 2.0177 - val_accuracy: 0.3348\n",
            "Epoch 19/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0613 - accuracy: 0.3591 - val_loss: 2.2321 - val_accuracy: 0.3455\n",
            "Epoch 20/20\n",
            "1389/1389 [==============================] - 4s 3ms/step - loss: 2.0625 - accuracy: 0.3646 - val_loss: 2.3425 - val_accuracy: 0.3179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:04:40,181]\u001b[0m Trial 9 finished with value: 0.31790000200271606 and parameters: {'learning_rate': 0.0032499865806224037, 'l2_regularization': 1.90077973775018e-05, 'batch_size': 36}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_10 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "5556/5556 [==============================] - 16s 3ms/step - loss: 2.1292 - accuracy: 0.2334 - val_loss: 2.0166 - val_accuracy: 0.2909\n",
            "Epoch 2/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.9701 - accuracy: 0.3123 - val_loss: 1.9394 - val_accuracy: 0.3254\n",
            "Epoch 3/20\n",
            "5556/5556 [==============================] - 16s 3ms/step - loss: 1.9146 - accuracy: 0.3360 - val_loss: 1.8996 - val_accuracy: 0.3401\n",
            "Epoch 4/20\n",
            "5556/5556 [==============================] - 16s 3ms/step - loss: 1.8829 - accuracy: 0.3481 - val_loss: 1.8742 - val_accuracy: 0.3486\n",
            "Epoch 5/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.8618 - accuracy: 0.3572 - val_loss: 1.8557 - val_accuracy: 0.3531\n",
            "Epoch 6/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.8466 - accuracy: 0.3623 - val_loss: 1.8433 - val_accuracy: 0.3593\n",
            "Epoch 7/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.8344 - accuracy: 0.3672 - val_loss: 1.8348 - val_accuracy: 0.3646\n",
            "Epoch 8/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.8248 - accuracy: 0.3706 - val_loss: 1.8262 - val_accuracy: 0.3648\n",
            "Epoch 9/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.8166 - accuracy: 0.3747 - val_loss: 1.8224 - val_accuracy: 0.3678\n",
            "Epoch 10/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.8096 - accuracy: 0.3755 - val_loss: 1.8125 - val_accuracy: 0.3723\n",
            "Epoch 11/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.8035 - accuracy: 0.3790 - val_loss: 1.8070 - val_accuracy: 0.3771\n",
            "Epoch 12/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.7978 - accuracy: 0.3802 - val_loss: 1.8019 - val_accuracy: 0.3768\n",
            "Epoch 13/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.7932 - accuracy: 0.3819 - val_loss: 1.7980 - val_accuracy: 0.3756\n",
            "Epoch 14/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.7885 - accuracy: 0.3842 - val_loss: 1.7959 - val_accuracy: 0.3807\n",
            "Epoch 15/20\n",
            "5556/5556 [==============================] - 16s 3ms/step - loss: 1.7844 - accuracy: 0.3857 - val_loss: 1.7890 - val_accuracy: 0.3849\n",
            "Epoch 16/20\n",
            "5556/5556 [==============================] - 16s 3ms/step - loss: 1.7808 - accuracy: 0.3888 - val_loss: 1.7885 - val_accuracy: 0.3846\n",
            "Epoch 17/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.7773 - accuracy: 0.3887 - val_loss: 1.7840 - val_accuracy: 0.3820\n",
            "Epoch 18/20\n",
            "5556/5556 [==============================] - 16s 3ms/step - loss: 1.7736 - accuracy: 0.3899 - val_loss: 1.7833 - val_accuracy: 0.3848\n",
            "Epoch 19/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.7711 - accuracy: 0.3920 - val_loss: 1.7783 - val_accuracy: 0.3888\n",
            "Epoch 20/20\n",
            "5556/5556 [==============================] - 15s 3ms/step - loss: 1.7679 - accuracy: 0.3925 - val_loss: 1.7755 - val_accuracy: 0.3876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:10:04,483]\u001b[0m Trial 10 finished with value: 0.38760000467300415 and parameters: {'learning_rate': 1.0168030975347438e-05, 'l2_regularization': 1.647845405724274e-05, 'batch_size': 9}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_11 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 2.1916 - accuracy: 0.1951 - val_loss: 2.0782 - val_accuracy: 0.2613\n",
            "Epoch 2/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 2.0222 - accuracy: 0.2868 - val_loss: 1.9824 - val_accuracy: 0.3045\n",
            "Epoch 3/20\n",
            "435/435 [==============================] - 1s 3ms/step - loss: 1.9565 - accuracy: 0.3187 - val_loss: 1.9393 - val_accuracy: 0.3191\n",
            "Epoch 4/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.9188 - accuracy: 0.3344 - val_loss: 1.9085 - val_accuracy: 0.3361\n",
            "Epoch 5/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.8931 - accuracy: 0.3463 - val_loss: 1.8883 - val_accuracy: 0.3441\n",
            "Epoch 6/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.8750 - accuracy: 0.3539 - val_loss: 1.8707 - val_accuracy: 0.3478\n",
            "Epoch 7/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.8616 - accuracy: 0.3593 - val_loss: 1.8588 - val_accuracy: 0.3551\n",
            "Epoch 8/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.8498 - accuracy: 0.3643 - val_loss: 1.8509 - val_accuracy: 0.3533\n",
            "Epoch 9/20\n",
            "435/435 [==============================] - 1s 3ms/step - loss: 1.8401 - accuracy: 0.3674 - val_loss: 1.8411 - val_accuracy: 0.3608\n",
            "Epoch 10/20\n",
            "435/435 [==============================] - 1s 3ms/step - loss: 1.8325 - accuracy: 0.3705 - val_loss: 1.8357 - val_accuracy: 0.3637\n",
            "Epoch 11/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.8252 - accuracy: 0.3715 - val_loss: 1.8268 - val_accuracy: 0.3690\n",
            "Epoch 12/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.8192 - accuracy: 0.3747 - val_loss: 1.8231 - val_accuracy: 0.3651\n",
            "Epoch 13/20\n",
            "435/435 [==============================] - 2s 3ms/step - loss: 1.8131 - accuracy: 0.3767 - val_loss: 1.8185 - val_accuracy: 0.3692\n",
            "Epoch 14/20\n",
            "435/435 [==============================] - 1s 3ms/step - loss: 1.8088 - accuracy: 0.3781 - val_loss: 1.8129 - val_accuracy: 0.3727\n",
            "Epoch 15/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.8041 - accuracy: 0.3800 - val_loss: 1.8094 - val_accuracy: 0.3723\n",
            "Epoch 16/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.7995 - accuracy: 0.3835 - val_loss: 1.8071 - val_accuracy: 0.3761\n",
            "Epoch 17/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.7954 - accuracy: 0.3846 - val_loss: 1.8046 - val_accuracy: 0.3795\n",
            "Epoch 18/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.7925 - accuracy: 0.3850 - val_loss: 1.7995 - val_accuracy: 0.3810\n",
            "Epoch 19/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.7890 - accuracy: 0.3868 - val_loss: 1.7969 - val_accuracy: 0.3772\n",
            "Epoch 20/20\n",
            "435/435 [==============================] - 2s 4ms/step - loss: 1.7857 - accuracy: 0.3873 - val_loss: 1.7939 - val_accuracy: 0.3838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:10:38,812]\u001b[0m Trial 11 finished with value: 0.3837999999523163 and parameters: {'learning_rate': 2.9505518878570335e-05, 'l2_regularization': 0.00010640091278631584, 'batch_size': 115}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_12 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "196/196 [==============================] - 2s 6ms/step - loss: 2.0950 - accuracy: 0.2493 - val_loss: 1.9650 - val_accuracy: 0.3079\n",
            "Epoch 2/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.9257 - accuracy: 0.3276 - val_loss: 1.8886 - val_accuracy: 0.3453\n",
            "Epoch 3/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.8743 - accuracy: 0.3503 - val_loss: 1.8605 - val_accuracy: 0.3581\n",
            "Epoch 4/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.8458 - accuracy: 0.3608 - val_loss: 1.8349 - val_accuracy: 0.3614\n",
            "Epoch 5/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.8272 - accuracy: 0.3688 - val_loss: 1.8201 - val_accuracy: 0.3673\n",
            "Epoch 6/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.8139 - accuracy: 0.3759 - val_loss: 1.8145 - val_accuracy: 0.3649\n",
            "Epoch 7/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.8034 - accuracy: 0.3796 - val_loss: 1.8058 - val_accuracy: 0.3711\n",
            "Epoch 8/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7927 - accuracy: 0.3848 - val_loss: 1.7949 - val_accuracy: 0.3805\n",
            "Epoch 9/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7861 - accuracy: 0.3858 - val_loss: 1.7926 - val_accuracy: 0.3760\n",
            "Epoch 10/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7813 - accuracy: 0.3877 - val_loss: 1.7852 - val_accuracy: 0.3832\n",
            "Epoch 11/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7733 - accuracy: 0.3895 - val_loss: 1.7824 - val_accuracy: 0.3822\n",
            "Epoch 12/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7703 - accuracy: 0.3918 - val_loss: 1.7718 - val_accuracy: 0.3885\n",
            "Epoch 13/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7644 - accuracy: 0.3943 - val_loss: 1.7765 - val_accuracy: 0.3847\n",
            "Epoch 14/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7612 - accuracy: 0.3956 - val_loss: 1.7658 - val_accuracy: 0.3888\n",
            "Epoch 15/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7570 - accuracy: 0.3964 - val_loss: 1.7680 - val_accuracy: 0.3926\n",
            "Epoch 16/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7531 - accuracy: 0.3991 - val_loss: 1.7633 - val_accuracy: 0.3921\n",
            "Epoch 17/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7489 - accuracy: 0.4017 - val_loss: 1.7607 - val_accuracy: 0.3931\n",
            "Epoch 18/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7453 - accuracy: 0.4031 - val_loss: 1.7588 - val_accuracy: 0.3956\n",
            "Epoch 19/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7432 - accuracy: 0.4046 - val_loss: 1.7561 - val_accuracy: 0.3910\n",
            "Epoch 20/20\n",
            "196/196 [==============================] - 1s 4ms/step - loss: 1.7420 - accuracy: 0.4023 - val_loss: 1.7612 - val_accuracy: 0.3867\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:11:01,494]\u001b[0m Trial 12 finished with value: 0.38670000433921814 and parameters: {'learning_rate': 0.0001228125483735409, 'l2_regularization': 9.552080222111936e-05, 'batch_size': 256}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_13 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "633/633 [==============================] - 4s 4ms/step - loss: 17.9348 - accuracy: 0.2233 - val_loss: 22.8418 - val_accuracy: 0.1753\n",
            "Epoch 2/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.9135 - accuracy: 0.2447 - val_loss: 16.5757 - val_accuracy: 0.2246\n",
            "Epoch 3/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.7896 - accuracy: 0.2521 - val_loss: 14.2988 - val_accuracy: 0.2699\n",
            "Epoch 4/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.4208 - accuracy: 0.2499 - val_loss: 14.9625 - val_accuracy: 0.3051\n",
            "Epoch 5/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.9567 - accuracy: 0.2494 - val_loss: 14.8514 - val_accuracy: 0.1980\n",
            "Epoch 6/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.6702 - accuracy: 0.2548 - val_loss: 8.3794 - val_accuracy: 0.2775\n",
            "Epoch 7/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.3873 - accuracy: 0.2538 - val_loss: 20.0230 - val_accuracy: 0.2099\n",
            "Epoch 8/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.0059 - accuracy: 0.2540 - val_loss: 19.0145 - val_accuracy: 0.2071\n",
            "Epoch 9/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.4353 - accuracy: 0.2495 - val_loss: 13.3951 - val_accuracy: 0.2263\n",
            "Epoch 10/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.8192 - accuracy: 0.2509 - val_loss: 17.7315 - val_accuracy: 0.1889\n",
            "Epoch 11/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.5946 - accuracy: 0.2507 - val_loss: 14.7736 - val_accuracy: 0.1878\n",
            "Epoch 12/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.9001 - accuracy: 0.2486 - val_loss: 16.9281 - val_accuracy: 0.2070\n",
            "Epoch 13/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.3162 - accuracy: 0.2488 - val_loss: 11.7903 - val_accuracy: 0.2662\n",
            "Epoch 14/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.0731 - accuracy: 0.2525 - val_loss: 10.3888 - val_accuracy: 0.2956\n",
            "Epoch 15/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.7628 - accuracy: 0.2530 - val_loss: 13.8267 - val_accuracy: 0.2396\n",
            "Epoch 16/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 12.9659 - accuracy: 0.2591 - val_loss: 14.7728 - val_accuracy: 0.2470\n",
            "Epoch 17/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.1819 - accuracy: 0.2498 - val_loss: 15.8400 - val_accuracy: 0.2250\n",
            "Epoch 18/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.0301 - accuracy: 0.2529 - val_loss: 19.7898 - val_accuracy: 0.2459\n",
            "Epoch 19/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 14.1782 - accuracy: 0.2529 - val_loss: 12.4190 - val_accuracy: 0.2626\n",
            "Epoch 20/20\n",
            "633/633 [==============================] - 2s 3ms/step - loss: 13.6495 - accuracy: 0.2520 - val_loss: 30.9940 - val_accuracy: 0.2217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:12:26,449]\u001b[0m Trial 13 finished with value: 0.22169999778270721 and parameters: {'learning_rate': 0.05332401889483072, 'l2_regularization': 0.0005262451424130207, 'batch_size': 79}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_14 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "981/981 [==============================] - 4s 4ms/step - loss: 2.1008 - accuracy: 0.2456 - val_loss: 1.9819 - val_accuracy: 0.3074\n",
            "Epoch 2/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.9403 - accuracy: 0.3231 - val_loss: 1.9089 - val_accuracy: 0.3418\n",
            "Epoch 3/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.8886 - accuracy: 0.3446 - val_loss: 1.8773 - val_accuracy: 0.3454\n",
            "Epoch 4/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.8594 - accuracy: 0.3553 - val_loss: 1.8575 - val_accuracy: 0.3504\n",
            "Epoch 5/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.8400 - accuracy: 0.3647 - val_loss: 1.8373 - val_accuracy: 0.3677\n",
            "Epoch 6/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.8258 - accuracy: 0.3699 - val_loss: 1.8259 - val_accuracy: 0.3677\n",
            "Epoch 7/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.8144 - accuracy: 0.3748 - val_loss: 1.8136 - val_accuracy: 0.3716\n",
            "Epoch 8/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.8049 - accuracy: 0.3771 - val_loss: 1.8060 - val_accuracy: 0.3746\n",
            "Epoch 9/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7972 - accuracy: 0.3821 - val_loss: 1.8043 - val_accuracy: 0.3703\n",
            "Epoch 10/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7904 - accuracy: 0.3829 - val_loss: 1.7985 - val_accuracy: 0.3735\n",
            "Epoch 11/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7846 - accuracy: 0.3867 - val_loss: 1.7954 - val_accuracy: 0.3811\n",
            "Epoch 12/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7794 - accuracy: 0.3877 - val_loss: 1.7867 - val_accuracy: 0.3849\n",
            "Epoch 13/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7746 - accuracy: 0.3889 - val_loss: 1.7859 - val_accuracy: 0.3817\n",
            "Epoch 14/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7700 - accuracy: 0.3921 - val_loss: 1.7802 - val_accuracy: 0.3795\n",
            "Epoch 15/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7656 - accuracy: 0.3932 - val_loss: 1.7748 - val_accuracy: 0.3865\n",
            "Epoch 16/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7628 - accuracy: 0.3962 - val_loss: 1.7736 - val_accuracy: 0.3826\n",
            "Epoch 17/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7589 - accuracy: 0.3966 - val_loss: 1.7691 - val_accuracy: 0.3891\n",
            "Epoch 18/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7561 - accuracy: 0.3964 - val_loss: 1.7675 - val_accuracy: 0.3896\n",
            "Epoch 19/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7536 - accuracy: 0.3979 - val_loss: 1.7690 - val_accuracy: 0.3907\n",
            "Epoch 20/20\n",
            "981/981 [==============================] - 3s 3ms/step - loss: 1.7500 - accuracy: 0.3998 - val_loss: 1.7627 - val_accuracy: 0.3892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:13:50,208]\u001b[0m Trial 14 finished with value: 0.38920000195503235 and parameters: {'learning_rate': 3.839985263979134e-05, 'l2_regularization': 7.547631537208845e-05, 'batch_size': 51}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_15 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.9560 - accuracy: 0.3199 - val_loss: 1.8525 - val_accuracy: 0.3587\n",
            "Epoch 2/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8739 - accuracy: 0.3572 - val_loss: 1.8541 - val_accuracy: 0.3638\n",
            "Epoch 3/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8466 - accuracy: 0.3704 - val_loss: 1.7938 - val_accuracy: 0.3951\n",
            "Epoch 4/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8349 - accuracy: 0.3767 - val_loss: 1.8301 - val_accuracy: 0.3876\n",
            "Epoch 5/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8269 - accuracy: 0.3746 - val_loss: 1.8229 - val_accuracy: 0.3735\n",
            "Epoch 6/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8184 - accuracy: 0.3817 - val_loss: 1.8113 - val_accuracy: 0.3784\n",
            "Epoch 7/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8141 - accuracy: 0.3845 - val_loss: 1.8627 - val_accuracy: 0.3523\n",
            "Epoch 8/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8142 - accuracy: 0.3845 - val_loss: 1.8186 - val_accuracy: 0.3858\n",
            "Epoch 9/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8064 - accuracy: 0.3888 - val_loss: 1.8094 - val_accuracy: 0.3723\n",
            "Epoch 10/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8098 - accuracy: 0.3858 - val_loss: 1.8021 - val_accuracy: 0.3810\n",
            "Epoch 11/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8037 - accuracy: 0.3893 - val_loss: 1.9403 - val_accuracy: 0.3391\n",
            "Epoch 12/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8051 - accuracy: 0.3883 - val_loss: 1.7981 - val_accuracy: 0.3784\n",
            "Epoch 13/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8014 - accuracy: 0.3888 - val_loss: 1.8405 - val_accuracy: 0.3694\n",
            "Epoch 14/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8044 - accuracy: 0.3887 - val_loss: 1.8677 - val_accuracy: 0.3429\n",
            "Epoch 15/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8032 - accuracy: 0.3899 - val_loss: 1.8361 - val_accuracy: 0.3705\n",
            "Epoch 16/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8004 - accuracy: 0.3907 - val_loss: 1.8331 - val_accuracy: 0.3661\n",
            "Epoch 17/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.7959 - accuracy: 0.3941 - val_loss: 1.8565 - val_accuracy: 0.3707\n",
            "Epoch 18/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.8020 - accuracy: 0.3907 - val_loss: 1.8654 - val_accuracy: 0.3563\n",
            "Epoch 19/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.7981 - accuracy: 0.3918 - val_loss: 1.7958 - val_accuracy: 0.4012\n",
            "Epoch 20/20\n",
            "3572/3572 [==============================] - 10s 3ms/step - loss: 1.7963 - accuracy: 0.3931 - val_loss: 1.9461 - val_accuracy: 0.3488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:17:14,018]\u001b[0m Trial 15 finished with value: 0.34880000352859497 and parameters: {'learning_rate': 0.00034503378566116944, 'l2_regularization': 0.0015784839408496333, 'batch_size': 14}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_16 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.3363 - accuracy: 0.2806 - val_loss: 2.0427 - val_accuracy: 0.3288\n",
            "Epoch 2/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2595 - accuracy: 0.2933 - val_loss: 2.2742 - val_accuracy: 0.2783\n",
            "Epoch 3/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2534 - accuracy: 0.2924 - val_loss: 2.1703 - val_accuracy: 0.3310\n",
            "Epoch 4/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2445 - accuracy: 0.2972 - val_loss: 2.1429 - val_accuracy: 0.2968\n",
            "Epoch 5/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2525 - accuracy: 0.2927 - val_loss: 2.7756 - val_accuracy: 0.2375\n",
            "Epoch 6/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2345 - accuracy: 0.2945 - val_loss: 2.4101 - val_accuracy: 0.2399\n",
            "Epoch 7/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2456 - accuracy: 0.2962 - val_loss: 2.0965 - val_accuracy: 0.3141\n",
            "Epoch 8/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2562 - accuracy: 0.2959 - val_loss: 2.2105 - val_accuracy: 0.2920\n",
            "Epoch 9/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2321 - accuracy: 0.2965 - val_loss: 2.1074 - val_accuracy: 0.3110\n",
            "Epoch 10/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2411 - accuracy: 0.2940 - val_loss: 2.4147 - val_accuracy: 0.2667\n",
            "Epoch 11/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2430 - accuracy: 0.2971 - val_loss: 2.2883 - val_accuracy: 0.2949\n",
            "Epoch 12/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2551 - accuracy: 0.2988 - val_loss: 2.4714 - val_accuracy: 0.3004\n",
            "Epoch 13/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2322 - accuracy: 0.2997 - val_loss: 2.5158 - val_accuracy: 0.2548\n",
            "Epoch 14/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2594 - accuracy: 0.2959 - val_loss: 2.1561 - val_accuracy: 0.3133\n",
            "Epoch 15/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2567 - accuracy: 0.2946 - val_loss: 2.1984 - val_accuracy: 0.2869\n",
            "Epoch 16/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2371 - accuracy: 0.2983 - val_loss: 2.3372 - val_accuracy: 0.2701\n",
            "Epoch 17/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2375 - accuracy: 0.2975 - val_loss: 2.2198 - val_accuracy: 0.3097\n",
            "Epoch 18/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2546 - accuracy: 0.2940 - val_loss: 1.9715 - val_accuracy: 0.3231\n",
            "Epoch 19/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2640 - accuracy: 0.2967 - val_loss: 2.3932 - val_accuracy: 0.2490\n",
            "Epoch 20/20\n",
            "2381/2381 [==============================] - 7s 3ms/step - loss: 2.2445 - accuracy: 0.2987 - val_loss: 2.2978 - val_accuracy: 0.2996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:19:37,786]\u001b[0m Trial 16 finished with value: 0.2996000051498413 and parameters: {'learning_rate': 0.002068430697640976, 'l2_regularization': 0.013082866052600799, 'batch_size': 21}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_17 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 3.3813 - accuracy: 0.2668 - val_loss: 2.0903 - val_accuracy: 0.3216\n",
            "Epoch 2/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.5876 - accuracy: 0.2967 - val_loss: 2.5514 - val_accuracy: 0.2527\n",
            "Epoch 3/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.8394 - accuracy: 0.3001 - val_loss: 2.5888 - val_accuracy: 0.3431\n",
            "Epoch 4/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.6253 - accuracy: 0.3067 - val_loss: 2.2438 - val_accuracy: 0.3106\n",
            "Epoch 5/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.6780 - accuracy: 0.3068 - val_loss: 2.9764 - val_accuracy: 0.2353\n",
            "Epoch 6/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.5276 - accuracy: 0.3169 - val_loss: 2.3475 - val_accuracy: 0.2966\n",
            "Epoch 7/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.6744 - accuracy: 0.3104 - val_loss: 2.2907 - val_accuracy: 0.3326\n",
            "Epoch 8/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.7070 - accuracy: 0.3150 - val_loss: 2.7739 - val_accuracy: 0.3355\n",
            "Epoch 9/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.5287 - accuracy: 0.3213 - val_loss: 2.4984 - val_accuracy: 0.3448\n",
            "Epoch 10/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.7253 - accuracy: 0.3142 - val_loss: 2.6255 - val_accuracy: 0.2771\n",
            "Epoch 11/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.6361 - accuracy: 0.3174 - val_loss: 2.1071 - val_accuracy: 0.3381\n",
            "Epoch 12/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.4712 - accuracy: 0.3284 - val_loss: 2.3730 - val_accuracy: 0.3277\n",
            "Epoch 13/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.6909 - accuracy: 0.3148 - val_loss: 2.7068 - val_accuracy: 0.2994\n",
            "Epoch 14/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.6629 - accuracy: 0.3172 - val_loss: 2.8876 - val_accuracy: 0.3483\n",
            "Epoch 15/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.5913 - accuracy: 0.3228 - val_loss: 3.3725 - val_accuracy: 0.2626\n",
            "Epoch 16/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.7573 - accuracy: 0.3169 - val_loss: 2.5599 - val_accuracy: 0.3001\n",
            "Epoch 17/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.6245 - accuracy: 0.3205 - val_loss: 2.5550 - val_accuracy: 0.3118\n",
            "Epoch 18/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.5676 - accuracy: 0.3246 - val_loss: 2.1288 - val_accuracy: 0.3407\n",
            "Epoch 19/20\n",
            "468/468 [==============================] - 2s 4ms/step - loss: 2.7302 - accuracy: 0.3186 - val_loss: 2.4899 - val_accuracy: 0.3023\n",
            "Epoch 20/20\n",
            "468/468 [==============================] - 2s 3ms/step - loss: 2.5593 - accuracy: 0.3267 - val_loss: 2.9693 - val_accuracy: 0.2636\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:20:20,582]\u001b[0m Trial 17 finished with value: 0.2635999917984009 and parameters: {'learning_rate': 0.011257902628968938, 'l2_regularization': 0.00027202604587881336, 'batch_size': 107}. Best is trial 1 with value: 0.39320001006126404.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_18 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 2.0452 - accuracy: 0.2685 - val_loss: 1.9273 - val_accuracy: 0.3303\n",
            "Epoch 2/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.8940 - accuracy: 0.3392 - val_loss: 1.8674 - val_accuracy: 0.3548\n",
            "Epoch 3/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.8516 - accuracy: 0.3562 - val_loss: 1.8366 - val_accuracy: 0.3628\n",
            "Epoch 4/20\n",
            "1191/1191 [==============================] - 3s 3ms/step - loss: 1.8271 - accuracy: 0.3664 - val_loss: 1.8190 - val_accuracy: 0.3692\n",
            "Epoch 5/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.8106 - accuracy: 0.3734 - val_loss: 1.8107 - val_accuracy: 0.3735\n",
            "Epoch 6/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7987 - accuracy: 0.3791 - val_loss: 1.7955 - val_accuracy: 0.3802\n",
            "Epoch 7/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7886 - accuracy: 0.3823 - val_loss: 1.7960 - val_accuracy: 0.3732\n",
            "Epoch 8/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7800 - accuracy: 0.3842 - val_loss: 1.7863 - val_accuracy: 0.3871\n",
            "Epoch 9/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7731 - accuracy: 0.3887 - val_loss: 1.7767 - val_accuracy: 0.3848\n",
            "Epoch 10/20\n",
            "1191/1191 [==============================] - 3s 3ms/step - loss: 1.7671 - accuracy: 0.3919 - val_loss: 1.7845 - val_accuracy: 0.3749\n",
            "Epoch 11/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7615 - accuracy: 0.3944 - val_loss: 1.7667 - val_accuracy: 0.3911\n",
            "Epoch 12/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7568 - accuracy: 0.3955 - val_loss: 1.7714 - val_accuracy: 0.3833\n",
            "Epoch 13/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7529 - accuracy: 0.3973 - val_loss: 1.7639 - val_accuracy: 0.3934\n",
            "Epoch 14/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7486 - accuracy: 0.4005 - val_loss: 1.7649 - val_accuracy: 0.3898\n",
            "Epoch 15/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7454 - accuracy: 0.4011 - val_loss: 1.7617 - val_accuracy: 0.3923\n",
            "Epoch 16/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7415 - accuracy: 0.4029 - val_loss: 1.7579 - val_accuracy: 0.3937\n",
            "Epoch 17/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7387 - accuracy: 0.4032 - val_loss: 1.7653 - val_accuracy: 0.3909\n",
            "Epoch 18/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7348 - accuracy: 0.4054 - val_loss: 1.7514 - val_accuracy: 0.3982\n",
            "Epoch 19/20\n",
            "1191/1191 [==============================] - 4s 3ms/step - loss: 1.7325 - accuracy: 0.4065 - val_loss: 1.7448 - val_accuracy: 0.3981\n",
            "Epoch 20/20\n",
            "1191/1191 [==============================] - 3s 3ms/step - loss: 1.7303 - accuracy: 0.4070 - val_loss: 1.7460 - val_accuracy: 0.3967\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:21:44,356]\u001b[0m Trial 18 finished with value: 0.396699994802475 and parameters: {'learning_rate': 5.612540938668213e-05, 'l2_regularization': 3.458436186709661e-05, 'batch_size': 42}. Best is trial 18 with value: 0.396699994802475.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_19 (Flatten)        (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 10)                30730     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,730\n",
            "Trainable params: 30,730\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "8334/8334 [==============================] - 26s 3ms/step - loss: 1.9724 - accuracy: 0.2962 - val_loss: 1.8685 - val_accuracy: 0.3459\n",
            "Epoch 2/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.8471 - accuracy: 0.3566 - val_loss: 1.8274 - val_accuracy: 0.3660\n",
            "Epoch 3/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.8141 - accuracy: 0.3706 - val_loss: 1.8078 - val_accuracy: 0.3670\n",
            "Epoch 4/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.7940 - accuracy: 0.3745 - val_loss: 1.8057 - val_accuracy: 0.3711\n",
            "Epoch 5/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.7801 - accuracy: 0.3827 - val_loss: 1.7785 - val_accuracy: 0.3808\n",
            "Epoch 6/20\n",
            "8334/8334 [==============================] - 25s 3ms/step - loss: 1.7695 - accuracy: 0.3890 - val_loss: 1.7821 - val_accuracy: 0.3717\n",
            "Epoch 7/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.7596 - accuracy: 0.3933 - val_loss: 1.7670 - val_accuracy: 0.3825\n",
            "Epoch 8/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.7530 - accuracy: 0.3965 - val_loss: 1.7649 - val_accuracy: 0.3845\n",
            "Epoch 9/20\n",
            "8334/8334 [==============================] - 25s 3ms/step - loss: 1.7459 - accuracy: 0.3968 - val_loss: 1.7724 - val_accuracy: 0.3908\n",
            "Epoch 10/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.7407 - accuracy: 0.4014 - val_loss: 1.7573 - val_accuracy: 0.3881\n",
            "Epoch 11/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.7348 - accuracy: 0.4046 - val_loss: 1.7670 - val_accuracy: 0.3852\n",
            "Epoch 12/20\n",
            "8334/8334 [==============================] - 25s 3ms/step - loss: 1.7313 - accuracy: 0.4040 - val_loss: 1.7422 - val_accuracy: 0.4018\n",
            "Epoch 13/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.7268 - accuracy: 0.4061 - val_loss: 1.7811 - val_accuracy: 0.3720\n",
            "Epoch 14/20\n",
            "8334/8334 [==============================] - 23s 3ms/step - loss: 1.7239 - accuracy: 0.4081 - val_loss: 1.7396 - val_accuracy: 0.3997\n",
            "Epoch 15/20\n",
            "8334/8334 [==============================] - 22s 3ms/step - loss: 1.7206 - accuracy: 0.4106 - val_loss: 1.7441 - val_accuracy: 0.3896\n",
            "Epoch 16/20\n",
            "8334/8334 [==============================] - 25s 3ms/step - loss: 1.7177 - accuracy: 0.4116 - val_loss: 1.7473 - val_accuracy: 0.3919\n",
            "Epoch 17/20\n",
            "8334/8334 [==============================] - 25s 3ms/step - loss: 1.7147 - accuracy: 0.4109 - val_loss: 1.7458 - val_accuracy: 0.3906\n",
            "Epoch 18/20\n",
            "8334/8334 [==============================] - 25s 3ms/step - loss: 1.7115 - accuracy: 0.4155 - val_loss: 1.7420 - val_accuracy: 0.3964\n",
            "Epoch 19/20\n",
            "8334/8334 [==============================] - 22s 3ms/step - loss: 1.7096 - accuracy: 0.4152 - val_loss: 1.7356 - val_accuracy: 0.3961\n",
            "Epoch 20/20\n",
            "8334/8334 [==============================] - 25s 3ms/step - loss: 1.7081 - accuracy: 0.4146 - val_loss: 1.7470 - val_accuracy: 0.3939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 07:29:38,812]\u001b[0m Trial 19 finished with value: 0.3939000070095062 and parameters: {'learning_rate': 4.1972047203366254e-05, 'l2_regularization': 3.851240270424532e-05, 'batch_size': 6}. Best is trial 18 with value: 0.396699994802475.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Study statistics: \n",
            "  Number of finished trials:  20\n",
            "  Number of pruned trials:  0\n",
            "  Number of complete trials:  20\n",
            "Best trial:\n",
            "  Value:  0.396699994802475\n",
            "  Params: \n",
            "    learning_rate: 5.612540938668213e-05\n",
            "    l2_regularization: 3.458436186709661e-05\n",
            "    batch_size: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Fully connectd Neural Network"
      ],
      "metadata": {
        "id": "hjsF_VvIkIc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_fnn_model(trial):\n",
        "    l2_regularization=trial.suggest_float(\"l2_regularization\", 1e-5, 1e-1, log=True)\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer(input_shape=x_train.shape[1:]))\n",
        "    model.add(Flatten())\n",
        "\n",
        "    n_layers = trial.suggest_int(\"n_layers\", 1, 4)\n",
        "    for i in range(n_layers):\n",
        "            num_hidden_exp = trial.suggest_int(\"n_units_l{}\".format(i), 4, 8)\n",
        "            num_hidden = int(np.pow(2, num_hidden_exp))\n",
        "            model.add(Dense(num_hidden, activation=\"relu\"))\n",
        "            dropout = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
        "            model.add(Dropout(rate=dropout))\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "def accuracy_fnn_mode(trial):\n",
        "    learning_rate=trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
        "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "    model = create_fnn_model(trial)\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    batch_size_exp = trial.suggest_int(\"batch_size\", 1, 8)\n",
        "    batch_size = int(np.pow(2, batch_size_exp))\n",
        "    history = model.fit(x_train, y_train,\n",
        "                batch_size=batch_size,\n",
        "                epochs=num_epochs,\n",
        "                validation_data=(x_test, y_test),\n",
        "                shuffle=True)\n",
        "\n",
        "    score = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return score[1]\n"
      ],
      "metadata": {
        "id": "TFfSYb93kH0u"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction=\"maximize\", pruner=optuna.pruners.MedianPruner())\n",
        "study.optimize(accuracy_fnn_mode, n_trials=100)\n",
        "pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
        "complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
        "\n",
        "print(\"Study statistics: \")\n",
        "print(\"  Number of finished trials: \", len(study.trials))\n",
        "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "print(\"Best trial:\")\n",
        "trial = study.best_trial\n",
        "\n",
        "print(\"  Value: \", trial.value)\n",
        "\n",
        "print(\"  Params: \")\n",
        "for key, value in trial.params.items():\n",
        "    print(\"    {}: {}\".format(key, value))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "p_PiREzImmgD",
        "outputId": "008897da-d817-44ac-bb37-9438cd63ef17"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-07-21 16:35:26,761]\u001b[0m A new study created in memory with name: no-name-182775c5-9a76-4376-ab01-570f724ac9ea\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 37)                113701    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 37)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 253)               9614      \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 253)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 27)                6858      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 27)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                280       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 130,453\n",
            "Trainable params: 130,453\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "1924/1924 [==============================] - 8s 4ms/step - loss: 2.3071 - accuracy: 0.1000 - val_loss: 2.3043 - val_accuracy: 0.1000\n",
            "Epoch 2/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3034 - accuracy: 0.0983 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 3/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3034 - accuracy: 0.0993 - val_loss: 2.3036 - val_accuracy: 0.1000\n",
            "Epoch 4/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3033 - accuracy: 0.1023 - val_loss: 2.3030 - val_accuracy: 0.1000\n",
            "Epoch 5/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3035 - accuracy: 0.1005 - val_loss: 2.3035 - val_accuracy: 0.1000\n",
            "Epoch 6/20\n",
            "1924/1924 [==============================] - 8s 4ms/step - loss: 2.3035 - accuracy: 0.0983 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 7/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3035 - accuracy: 0.0973 - val_loss: 2.3031 - val_accuracy: 0.1000\n",
            "Epoch 8/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3034 - accuracy: 0.1000 - val_loss: 2.3029 - val_accuracy: 0.1000\n",
            "Epoch 9/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3034 - accuracy: 0.0984 - val_loss: 2.3033 - val_accuracy: 0.1000\n",
            "Epoch 10/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3036 - accuracy: 0.1003 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 11/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3034 - accuracy: 0.0980 - val_loss: 2.3028 - val_accuracy: 0.1000\n",
            "Epoch 12/20\n",
            "1924/1924 [==============================] - 7s 4ms/step - loss: 2.3033 - accuracy: 0.1011 - val_loss: 2.3032 - val_accuracy: 0.1000\n",
            "Epoch 13/20\n",
            " 723/1924 [==========>...................] - ETA: 3s - loss: 2.3032 - accuracy: 0.1035"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-a2a5262e4145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpruner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMedianPruner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy_fnn_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpruned_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRUNED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcomplete_trials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-ec9d011473fe>\u001b[0m in \u001b[0;36maccuracy_fnn_mode\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m                 shuffle=True)\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1382\u001b[0m                 _r=1):\n\u001b[1;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1384\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1385\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}